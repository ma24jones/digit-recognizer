{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and target variables\n",
    "X = train.iloc[:,:-1]\n",
    "y = train.iloc[:,-1:]\n",
    "y = train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (37800, 784)\n",
      "y_train.shape:  (37800,)\n",
      "X_test.shape:  (4200, 784)\n",
      "y_test.shape:  (4200,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing values\n",
    "X_train = X_train.values/255\n",
    "X_test = X_test.values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to torch tensors\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "batch = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(128, 224, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop2): Dropout(p=0.4, inplace=False)\n",
      "  (fc3): Linear(in_features=3584, out_features=64, bias=True)\n",
      "  (drop3): Dropout(p=0.4, inplace=False)\n",
      "  (fc4): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (drop4): Dropout(p=0.4, inplace=False)\n",
      "  (fc5): Linear(in_features=32, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Architecture\n",
    "\n",
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 128, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(128, 224, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.drop2 = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.fc3 = nn.Linear(224*4*4, 64)\n",
    "        self.drop3 = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.drop4 = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.fc5 = nn.Linear(32, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.pool1(F.relu(self.conv1(x))))\n",
    "        x = self.drop2(self.pool2(F.relu(self.conv2(x))))\n",
    "        \n",
    "        x = x.view(-1,224*4*4)\n",
    "        \n",
    "        x = self.drop3(F.relu(self.fc3(x)))\n",
    "        x = self.drop4(F.relu(self.fc4(x)))\n",
    "        \n",
    "        x = self.softmax(self.fc5(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "print(Net()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making an object of the Net class\n",
    "model = Net().to(device)\n",
    "\n",
    "#Loss function\n",
    "criterion = nn.CrossEntropyLoss ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3..  Test Accuracy: 0.793\n",
      "Epoch: 1/3..  Test Accuracy: 0.820\n",
      "Epoch: 1/3..  Test Accuracy: 0.877\n",
      "Epoch: 1/3..  Test Accuracy: 0.917\n",
      "Epoch: 1/3..  Test Accuracy: 0.889\n",
      "Epoch: 1/3..  Test Accuracy: 0.904\n",
      "Epoch: 1/3..  Test Accuracy: 0.922\n",
      "Epoch: 1/3..  Test Accuracy: 0.905\n",
      "Epoch: 1/3..  Test Accuracy: 0.900\n",
      "Epoch: 1/3..  Test Accuracy: 0.886\n",
      "Epoch: 1/3..  Test Accuracy: 0.929\n",
      "Epoch: 1/3..  Test Accuracy: 0.936\n",
      "Epoch: 1/3..  Test Accuracy: 0.924\n",
      "Epoch: 1/3..  Test Accuracy: 0.927\n",
      "Epoch: 1/3..  Test Accuracy: 0.926\n",
      "Epoch: 1/3..  Test Accuracy: 0.933\n",
      "Epoch: 1/3..  Test Accuracy: 0.923\n",
      "Epoch: 1/3..  Test Accuracy: 0.930\n",
      "Epoch: 1/3..  Test Accuracy: 0.902\n",
      "Epoch: 1/3..  Test Accuracy: 0.938\n",
      "Epoch: 1/3..  Test Accuracy: 0.930\n",
      "Epoch: 1/3..  Test Accuracy: 0.936\n",
      "Epoch: 1/3..  Test Accuracy: 0.926\n",
      "Epoch: 1/3..  Test Accuracy: 0.930\n",
      "Epoch: 1/3..  Test Accuracy: 0.930\n",
      "Epoch: 1/3..  Test Accuracy: 0.938\n",
      "Epoch: 1/3..  Test Accuracy: 0.927\n",
      "Epoch: 1/3..  Test Accuracy: 0.939\n",
      "Epoch: 1/3..  Test Accuracy: 0.941\n",
      "Epoch: 1/3..  Test Accuracy: 0.939\n",
      "Epoch: 1/3..  Test Accuracy: 0.938\n",
      "Epoch: 1/3..  Test Accuracy: 0.936\n",
      "Epoch: 1/3..  Test Accuracy: 0.919\n",
      "Epoch: 1/3..  Test Accuracy: 0.944\n",
      "Epoch: 1/3..  Test Accuracy: 0.933\n",
      "Epoch: 1/3..  Test Accuracy: 0.938\n",
      "Epoch: 1/3..  Test Accuracy: 0.915\n",
      "Epoch: 2/3..  Test Accuracy: 0.923\n",
      "Epoch: 2/3..  Test Accuracy: 0.941\n",
      "Epoch: 2/3..  Test Accuracy: 0.928\n",
      "Epoch: 2/3..  Test Accuracy: 0.948\n",
      "Epoch: 2/3..  Test Accuracy: 0.948\n",
      "Epoch: 2/3..  Test Accuracy: 0.946\n",
      "Epoch: 2/3..  Test Accuracy: 0.941\n",
      "Epoch: 2/3..  Test Accuracy: 0.931\n",
      "Epoch: 2/3..  Test Accuracy: 0.950\n",
      "Epoch: 2/3..  Test Accuracy: 0.934\n",
      "Epoch: 2/3..  Test Accuracy: 0.943\n",
      "Epoch: 2/3..  Test Accuracy: 0.947\n",
      "Epoch: 2/3..  Test Accuracy: 0.944\n",
      "Epoch: 2/3..  Test Accuracy: 0.950\n",
      "Epoch: 2/3..  Test Accuracy: 0.936\n",
      "Epoch: 2/3..  Test Accuracy: 0.946\n",
      "Epoch: 2/3..  Test Accuracy: 0.938\n",
      "Epoch: 2/3..  Test Accuracy: 0.943\n",
      "Epoch: 2/3..  Test Accuracy: 0.948\n",
      "Epoch: 2/3..  Test Accuracy: 0.949\n",
      "Epoch: 2/3..  Test Accuracy: 0.942\n",
      "Epoch: 2/3..  Test Accuracy: 0.939\n",
      "Epoch: 2/3..  Test Accuracy: 0.932\n",
      "Epoch: 2/3..  Test Accuracy: 0.927\n",
      "Epoch: 2/3..  Test Accuracy: 0.933\n",
      "Epoch: 2/3..  Test Accuracy: 0.933\n",
      "Epoch: 2/3..  Test Accuracy: 0.926\n",
      "Epoch: 2/3..  Test Accuracy: 0.941\n",
      "Epoch: 2/3..  Test Accuracy: 0.920\n",
      "Epoch: 2/3..  Test Accuracy: 0.934\n",
      "Epoch: 2/3..  Test Accuracy: 0.915\n",
      "Epoch: 2/3..  Test Accuracy: 0.907\n",
      "Epoch: 2/3..  Test Accuracy: 0.929\n",
      "Epoch: 2/3..  Test Accuracy: 0.938\n",
      "Epoch: 2/3..  Test Accuracy: 0.942\n",
      "Epoch: 2/3..  Test Accuracy: 0.942\n",
      "Epoch: 2/3..  Test Accuracy: 0.944\n",
      "Epoch: 2/3..  Test Accuracy: 0.953\n",
      "Epoch: 3/3..  Test Accuracy: 0.945\n",
      "Epoch: 3/3..  Test Accuracy: 0.917\n",
      "Epoch: 3/3..  Test Accuracy: 0.944\n",
      "Epoch: 3/3..  Test Accuracy: 0.943\n",
      "Epoch: 3/3..  Test Accuracy: 0.949\n",
      "Epoch: 3/3..  Test Accuracy: 0.943\n",
      "Epoch: 3/3..  Test Accuracy: 0.932\n",
      "Epoch: 3/3..  Test Accuracy: 0.945\n",
      "Epoch: 3/3..  Test Accuracy: 0.935\n",
      "Epoch: 3/3..  Test Accuracy: 0.948\n",
      "Epoch: 3/3..  Test Accuracy: 0.922\n",
      "Epoch: 3/3..  Test Accuracy: 0.945\n",
      "Epoch: 3/3..  Test Accuracy: 0.949\n",
      "Epoch: 3/3..  Test Accuracy: 0.935\n",
      "Epoch: 3/3..  Test Accuracy: 0.945\n",
      "Epoch: 3/3..  Test Accuracy: 0.949\n",
      "Epoch: 3/3..  Test Accuracy: 0.938\n",
      "Epoch: 3/3..  Test Accuracy: 0.954\n",
      "Epoch: 3/3..  Test Accuracy: 0.948\n",
      "Epoch: 3/3..  Test Accuracy: 0.945\n",
      "Epoch: 3/3..  Test Accuracy: 0.924\n",
      "Epoch: 3/3..  Test Accuracy: 0.937\n",
      "Epoch: 3/3..  Test Accuracy: 0.914\n",
      "Epoch: 3/3..  Test Accuracy: 0.931\n",
      "Epoch: 3/3..  Test Accuracy: 0.919\n",
      "Epoch: 3/3..  Test Accuracy: 0.936\n",
      "Epoch: 3/3..  Test Accuracy: 0.935\n",
      "Epoch: 3/3..  Test Accuracy: 0.935\n",
      "Epoch: 3/3..  Test Accuracy: 0.948\n",
      "Epoch: 3/3..  Test Accuracy: 0.951\n",
      "Epoch: 3/3..  Test Accuracy: 0.945\n",
      "Epoch: 3/3..  Test Accuracy: 0.947\n",
      "Epoch: 3/3..  Test Accuracy: 0.930\n",
      "Epoch: 3/3..  Test Accuracy: 0.926\n",
      "Epoch: 3/3..  Test Accuracy: 0.906\n",
      "Epoch: 3/3..  Test Accuracy: 0.941\n",
      "Epoch: 3/3..  Test Accuracy: 0.930\n",
      "Epoch: 3/3..  Test Accuracy: 0.945\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0015)\n",
    "\n",
    "# Initialising variables\n",
    "epochs = 3\n",
    "steps = 0\n",
    "print_every = 100\n",
    "trainLoss = [] \n",
    "testLoss = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        steps += 1   # Forward pass\n",
    "        \n",
    "        images = (images.view(-1,1,28,28)).type(torch.DoubleTensor)\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(images.type(torch.FloatTensor).to(device))\n",
    "        labels = labels.to(device)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()   # Backward pass\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for images, labels in test_loader:\n",
    "                    images = (images.view(-1,1,28,28)).type(torch.DoubleTensor)\n",
    "                    log_ps = model(images.type(torch.FloatTensor).to(device))\n",
    "                    labels = labels.to(device)\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    \n",
    "                    top_p, top_class = ps.topk(1, dim = 1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            trainLoss.append(running_loss/len(train_loader))\n",
    "            testLoss.append(test_loss/len(test_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e + 1, epochs),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "finalTest = test.values/255\n",
    "\n",
    "finalTest = torch.from_numpy(finalTest)\n",
    "\n",
    "temp = np.zeros(finalTest.shape)\n",
    "temp = torch.from_numpy(temp)\n",
    "\n",
    "data = torch.utils.data.TensorDataset(finalTest, temp)\n",
    "\n",
    "submissionLoader = torch.utils.data.DataLoader(data, batch_size = batch, shuffle = False)\n",
    "\n",
    "submission = [['ImageId', 'Label']]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    image_id = 1\n",
    "    for images, _ in submissionLoader:\n",
    "        images = (images.view(-1,1,28,28)).type(torch.DoubleTensor)\n",
    "        log_ps = model(images.type(torch.FloatTensor).to(device))\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        \n",
    "        for prediction in top_class:\n",
    "            submission.append([image_id, prediction.item()])\n",
    "            image_id += 1\n",
    "            \n",
    "\n",
    "\n",
    "pytorchSubmission = pd.DataFrame(submission)\n",
    "pytorchSubmission.columns = pytorchSubmission.iloc[0]\n",
    "pytorchSubmission = pytorchSubmission.drop(0, axis = 0)\n",
    "\n",
    "pytorchSubmission.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db34128572869323ddfb2fac25796155b5136ad1642697417b30880cf3a07244"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}